<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 27]
- [cs.CV](#cs.CV) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 首次系统性评估大语言模型在意大利语性别中性改写任务中的表现，开放源模型超过专门模型，细调模型在小规模下达到相似性能


<details>
  <summary>Details</summary>
Motivation: 解决语法性别语言(如意大利语)中性别中性改写的挑战，缺乏对大语言模型在该任务上的系统性评估

Method: 构建二维评估框架(中性性和语义忠实度)，比较少样本提示、细调选择模型并应用目标清理技术

Result: 开放权重LLM在意大利语GNR中超过专门模型，细调模型在小规模下达到相似或更好性能

Conclusion: 展示了在优化训练数据中性性和意义保持之间的权衡关系，为语法性别语言的性别中性改写提供了有效解决方案

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [2] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: Op-Fed数据集包含1044条人工标注的FOMC会议记录句子，用于货币政策立场分析，解决了类别不平衡和句子间依赖的技术挑战。


<details>
  <summary>Details</summary>
Motivation: FOMC货币政策决策影响数百万人，但缺乏高质量的标注数据集来分析政策立场表达。

Method: 开发五阶段分层标注框架，使用主动学习选择标注实例，解决类别不平衡问题。

Result: 顶级闭源LLM在观点分类上达到0.80准确率，但在货币政策立场分类上仅0.61，低于人类基准0.89。

Conclusion: Op-Fed数据集可用于模型训练、置信度校准和作为未来标注工作的种子数据集。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [3] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1 针对对话系统评估的两个关键挑战：多维度自动评估和多语言文化安全检测，建立了基准测试和基线模型，结果显示当前方法在多维度评估方面仍有很大改进空间，在文化安全意识方面存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展凸显了对话系统评估的迫切需求，但传统评估指标不足，安全考虑往往定义狭窄或存在文化偏见，需要建立更全面、多维度、跨文化的评估框架。

Method: 通过DSTC12 Track 1竞赛设置两个子任务：1）对话级多维度自动评估指标（10个维度），2）多语言和多文化安全检测。提供数据集和基线模型（Llama-3-8B和Llama-Guard-3-1B），收集参赛团队提交的方案进行评估比较。

Result: 任务1中Llama-3-8B基线模型获得最高平均Spearman相关系数0.1681，表明多维度评估仍有很大改进空间。任务2中参赛团队在多语言安全子集上显著优于基线（最佳ROC-AUC 0.9648），但在文化子集上基线表现更好（0.5126 ROC-AUC），凸显文化安全意识的关键需求。

Conclusion: 当前对话系统评估在多维度自动评估和文化安全意识方面都存在显著挑战，需要进一步研究开发更全面、文化敏感的评估方法，DSTC12 Track 1为此提供了重要的基准和方向指引。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [4] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 这篇论文提出了一个分析框架，通过构建迁移学习矩阵和降维技术来探索跨任务转移学习的潜在能力和副作用，发现隐藏统计因素比表面数据相似性更关键。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在实际部署中经常遇到训练时未见过的任务，需要依靠较差质量数据进行转移学习，因此需要理解跨任务转移学习的复杂动态。

Method: 构建转移学习矩阵并使用降维技术，训练分析10个模型来识别潜在能力（如推理、情感分类、自然语言理解、算术等）和转移学习的副作用。

Result: 发现性能改善并不取决于表面数据相似性或源数据质量，而是由源数据集的隐藏统计因素（如类分布、生成长度偏好）和特定语言特征更具影响力。

Conclusion: 这个工作揭示了转移学习的复杂动态，为更可预测和有效的大语言模型适配抓基础。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [5] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: LLMs内部神经元线性编码问题歧义性，少数神经元即可检测和控制歧义性，使模型从直接回答转为弃权


<details>
  <summary>Details</summary>
Motivation: 现实问题普遍存在歧义性，但LLMs往往自信回答而非寻求澄清，需要研究模型内部如何表示和处理歧义性

Method: 在模型预填充阶段识别歧义编码神经元(AENs)，训练探针进行歧义检测，通过操纵AENs控制模型行为

Result: AENs探针在歧义检测上表现优异且跨数据集泛化能力强，歧义信号在浅层早期编码，通过神经元操纵可控制模型回答行为

Conclusion: LLMs形成紧凑的内部歧义性表示，支持可解释和可控的行为，为模型歧义处理机制提供了新见解

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [6] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 提出了首个中文文献语法纠错持续学习基准CL²GEC，包含10个学科的10,000条标注句子，评估LLM在跨学科语法纠错中的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错研究缺乏多学科学术写作的专门基准，忽视了持续学习在处理领域特定语言变异和防止灾难性遗忘方面的潜力。

Method: 构建包含10个学科10,000句的标注数据集，在持续学习设置下评估大语言模型，包括顺序调优、参数高效适应和四种代表性CL算法。

Result: 实验结果表明，基于正则化的方法比基于回放或简单顺序方法更能有效缓解遗忘问题。

Conclusion: 该基准为跨学科学术领域的自适应语法纠错研究提供了严谨的基础。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [7] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG是一个新颖的可扩展框架，通过模拟多智能体工作流中的控制和调节机制，实现对文本生成的精确复杂控制。该方法在多个公开数据集上达到最先进水平，并在角色驱动重写任务中验证了实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 尽管NLP领域在许多任务上取得显著进展，但受控文本生成(CTG)仍面临诸多挑战，特别是在实现细粒度条件控制方面。实际应用场景中还需要考虑成本、可扩展性、领域知识学习和更精确的控制。

Method: 提出AgentCTG框架，通过模拟多智能体工作流中的控制和调节机制来增强文本生成的精确控制。探索不同智能体间的协作方法，并引入自动提示模块进一步提升生成效果。

Result: 在多个公开数据集上达到最先进结果。提出的角色驱动重写任务验证了方法的实际应用价值，在在线导航角色扮演中显著提升了驾驶体验和内容交付效果。

Conclusion: AgentCTG框架通过多智能体协作机制有效解决了受控文本生成中的精确控制挑战，为在线社区提供了更沉浸式的交互体验，促进了个性化和用户参与度。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [8] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: CARE框架通过教导LLM在推理过程中显式整合上下文证据，显著提升了检索准确性和答案生成性能，无需昂贵的监督微调


<details>
  <summary>Details</summary>
Motivation: 解决LLM在基于给定信息回答问题时存在的上下文保真度问题，现有方法要么需要昂贵的监督微调，要么无法有效利用给定上下文

Method: 提出CARE框架，教导LLM利用自身检索能力在推理链中显式整合上下文证据，仅需少量标注证据数据

Result: 在多个真实世界和反事实QA基准测试中显著优于监督微调、传统检索增强生成方法和外部检索解决方案

Conclusion: 这项工作是使LLM在知识密集型任务中更加准确、可靠和高效的根本性进步

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [9] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本文构建了一个专注于比较级的日语NLI数据集，评估了各种LLM在零样本和少样本设置下的表现，发现模型对提示格式敏感，且在处理日语特有语言现象时存在困难，但包含逻辑语义表示的提示能帮助模型解决困难推理问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言推理方面表现优异，但涉及数值和逻辑表达式的推理仍然具有挑战性。比较级是与此类推理相关的关键语言现象，但LLM在处理比较级方面的鲁棒性，特别是在训练数据中非主导语言（如日语）中的表现尚未得到充分探索。

Method: 构建了一个专注于比较级的日语NLI数据集，并在零样本和少样本设置下评估了各种LLM。分析了不同提示格式的影响以及少样本示例中黄金标签的影响。

Result: 模型在零样本设置中对提示格式敏感，在少样本设置中受到黄金标签的影响。LLM在处理日语特有语言现象时存在困难。包含逻辑语义表示的提示能帮助模型预测那些即使在少样本示例下也难以解决的推理问题的正确标签。

Conclusion: 研究表明LLM在处理日语比较级推理时存在局限性，但通过适当的提示工程（特别是包含逻辑语义表示）可以显著提升模型性能，这为改进多语言NLI任务提供了重要见解。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [10] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 使用DSPy提示优化技术，将指令调优的大语言模型应用于临床分类任务，能够同时处理临床文本和结构化EHR数据，性能媲美专业多模态系统且更简单灵活


<details>
  <summary>Details</summary>
Motivation: 大语言模型在文本生成方面表现出色，但在处理包含时间序列等结构化数据的临床分类任务方面仍有待探索

Method: 采用基于DSPy的提示优化技术，对指令调优的大语言模型进行适配，使其能够联合处理临床笔记和结构化EHR输入

Result: 该方法在性能上与专业的多模态系统相当，同时具有更低的复杂度和更强的跨任务适应性

Conclusion: 通过提示优化技术，大语言模型可以有效处理临床分类任务，为医疗AI应用提供了更简单灵活的解决方案

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [11] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: DSCC-HS是一种新颖的主动式幻觉抑制框架，通过在自回归解码过程中注入实时转向向量来动态校准大语言模型的输出，无需修改目标模型即可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型幻觉问题是可靠部署的关键障碍，现有方法如RAG多为被动反应式，需要更主动的干预方法。

Method: 基于双过程认知理论，使用紧凑代理模型分别作为事实对齐代理(FAP)和幻觉检测代理(HDP)，在推理时通过计算两者logits差异生成实时转向向量，动态引导目标模型。

Result: 在TruthfulQA上达到99.2%的事实一致性率，在BioGEN长文本基准上获得最高FActScore 46.50，实现了最先进的性能。

Conclusion: DSCC-HS提供了一个原则性且高效的解决方案，能够显著增强大语言模型的事实性，具有即插即用的优势。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [12] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 使用NLP技术开发了一种能够识别放射治疗中高严重度事故报告的跨机构模型，性能接近人类专家水平


<details>
  <summary>Details</summary>
Motivation: 手动审查医疗事故报告耗时耗力且需要专业知识，需要自动化工具来提高效率

Method: 使用两个机构的7,094份报告训练NLP模型，包括SVM和BlueBERT模型，并采用跨机构转移学习技术

Result: 跨机构转移学习后的BlueBERT模型在测试集上达到AUROC 0.78，性能接近人类专家的AUROC 0.81

Conclusion: 成功开发了能够跨机构识别高严重度事故报告的NLP模型，性能与人类专家相似

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [13] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 基于过滤和剪枝的两阶段无训练提示压缩方法DSPC，在保持语义的前提下显著减少计算成本，性能超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型提示迅速增长导致计算成本高的问题，而现有压缩方法多需训练辅助模型，增加了计算开销。

Method: 提出双阶段渐进式压缩方法DSPC：粗粒度阶段使用TF-IDF过滤低语义值句子；细粒度阶段统考关注贡献度、跨模型损失差异和位置重要性来剪枝低效用token。

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上验证，在仅使用3倍更少token的情况下，Longbench数据集FewShot任务中达到49.17性能，超过最佳现有方法LongLLMLingua 7.76。

Conclusion: DSPC方法无需训练、效果显著，能在大幅减少计算成本的同时保持语义完整性，为提示压缩提供了高效解决方案。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [14] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于组合语义的日语比较句逻辑推理系统ccg-jcomp，以解决日语比较句在自然语言推理中的挑战。


<details>
  <summary>Details</summary>
Motivation: 日语和英语比较句在语法和语义上存在显著差异，使得现有的逻辑推理系统无法直接应用于日语比较句。需要专门为日语设计一种稳健的推理方法。

Method: 基于组合语义学的逻辑推理系统，专门为日语比较句设计。通过对比语义表达和数量关系的深度理解来实现推理。

Result: 在日语比较句NLI数据集上评估，并与现有大语言模型进行了准确率对比。结果显示该系统具有有效性。

Conclusion: 通过组合语义方法构建的逻辑推理系统能够有效处理日语比较句的自然语言推理任务，为日语语义理解提供了可靠的解决方案。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [15] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探索了阿拉伯方言识别的数据效率和参数效率方法，包括软提示策略和LoRA重参数化，发现LoRA精调模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究阿拉伯方言识别任务中的数据效率和参数效率方法，以提高大语言模型在方言区分任务上的性能。

Method: 采用多种软提示策略（前缀调整、提示调整、P调整等）和LoRA重参数化，在阿拉伯特定编码器模型和解码器模型上进行实验。

Result: 大语言模型在零小样本推理中区分方言细微差异能力不佳，软提示编码器表现更好，LoRA精调模型表现最好且超越全量精调。

Conclusion: LoRA基于的参数效率精调方法在阿拉伯方言识别任务上表现最优，而大语言模型在少样本场景下对方言细微差异的区分能力有限。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [16] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: CAMPUS框架通过动态选择子课程、能力感知的课程进度调整和多维度难度调度，解决了传统课程学习中课程刚性问题，显著提升了指令调优效果


<details>
  <summary>Details</summary>
Motivation: 当前课程学习方法依赖静态启发式难度指标，存在课程刚性问题，无法适应模型在训练过程中不断演进的能力，导致固定且可能次优的学习轨迹

Method: 提出CAMPUS框架，包含三个核心优势：1）动态选择子课程；2）基于能力感知调整课程进度；3）多维度难度调度策略

Result: 大量实验证明CAMPUS在高效指令调优方面优于其他最先进的基线方法

Conclusion: CAMPUS通过动态适应模型能力演进，有效解决了课程刚性问题，为指令调优提供了更优的学习轨迹

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [17] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 本文研究语法性别在职业名称中的显式分配如何影响自动职业排名系统，提出了用RBO指标评估性别偏见，并在4种语言中创建了包含阳性/阴性形式职业名称的测试集。


<details>
  <summary>Details</summary>
Motivation: 研究语法性别在职业名称中的显式分配对自动职业排名系统结果的影响，评估多语言模型在职业匹配任务中的性别偏见问题。

Method: 提出使用RBO(Rank-Biased Overlap)指标来评估职业名称排名系统中的性别偏见，在4种具有语法性别的语言中创建包含阳性和阴性形式职业名称的测试数据集，并用于评估多个外部多语言模型。

Result: 所有测试的外部多语言模型都不同程度地展现出性别偏见，证明了语法性别对自动职业排名系统的影响。

Conclusion: 该研究为评估职业名称排名系统中的性别偏见提供了基础方法和工具，并证实了现有多语言模型在这一问题上的存在问题，为以后的偏见消除工作奠定了基础。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [18] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 通过几何框架提出全局和局部不确定性量化方法，解决了黑盒模型不确定性评估的问题


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，需要不确定性量化来检测幻觉，但现有黑盒方法只能提供全局不确定性估计

Method: 基于响应嵌入的原型分析，提出Geometric Volume（几何体积）测量全局不确定性，Geometric Suspicion（几何疑惑）排序应响可靠性

Result: 在短形式问答数据集上表现类似或更优于现有方法，在医疗数据集上获得更优异的结果

Conclusion: 该几何框架为黑盒模型提供了合成的全局和局部不确定性量化方法，有效地检测幻觉现象

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [19] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: AutoMin 2025共享任务，包含会议纪要生成和问答两个任务，涵盖英语和捷克语，参与团队较少但包含多个LLM基线系统评估


<details>
  <summary>Details</summary>
Motivation: 推进自动会议纪要生成技术，探索结构化会议记录和基于会议转录的问答能力，评估当前大语言模型在这两个任务上的表现

Method: 组织共享任务，设置两个主要任务：会议纪要生成（涵盖英语和捷克语的项目会议和欧洲议会会议）和问答任务（单语英语问答和跨语言捷克语问答）。包含多个基线系统进行综合评估

Result: 2025年参与度较低，只有1个团队参加纪要生成任务，2个团队参加问答任务。但通过组织者提供的多个基线系统，实现了对当前大语言模型的全面评估

Conclusion: 尽管参与团队有限，但AutoMin 2025成功评估了当前LLM在自动会议纪要生成和问答任务上的能力，为相关研究提供了有价值的基准

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [20] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 这篇论文研究大语言模型对德国方言语者的偏见，发现LLMs在联想任务和决策任务中都存在显著的方言名称和使用偏见，且明确标注语言人口统计特征会更大程度放大偏见。


<details>
  <summary>Details</summary>
Motivation: 方言作为人类文化的重要组成部分，语言者却面临负面社会定型。研究考察大语言模型是否也存在类似的方言偏见问题。

Method: 基于社会语言学文献构建方言语者特征分析，通过联想任务和决策任务评估LLMs的方言名称偏见和方言使用偏见，构建了包含七种德国地区方言的新题评估语料库。

Result: 所有评估的LLMs都显示出显著的方言名称和使用偏见（负面形容词联想），所有模型都在决策中复现了这些偏见，明确标注语言人口统计特征比隐含线索更大程度放大偏见。

Conclusion: 大语言模型存在对德国方言语者的系统性偏见，这种偏见在明确标注语言人口特征时会更加严重，呈现出与社会定型相似的负面偏见模式。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [21] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在社交偏见方面与人类价值观存在错位，模型规模大不一定意味着更好的对齐效果，不同模型家族在特定场景类型上表现出对齐偏好和一致性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型在不同类型偏见场景中与人类价值观的对齐情况，特别是负面与非负面问题场景下的差异，以及模型对社交偏见价值观的理解能力。

Method: 通过对4个模型家族的12个LLM进行广泛分析，使用4个数据集评估模型在偏见场景中的对齐表现，并研究模型对HVSB的解释能力，同时通过微调赋予小模型解释能力。

Result: 大参数规模的LLM不一定具有更低的错位率和攻击成功率；模型对特定类型场景表现出对齐偏好；同一模型家族的模型判断一致性更高；不同LLM对HVSB的理解无显著差异；模型偏好自身生成的解释；微调后的小模型生成更易读但模型认同度较低的解释。

Conclusion: LLM与人类价值观的对齐效果受场景类型影响，模型规模不是决定性因素，需要针对不同场景类型进行专门的对齐优化，同时小模型通过微调可以获得解释能力但需要提升模型认同度。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [22] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER框架结合科学证据检索、大语言模型推理和监督真实性预测，用于生物医学事实核查，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域中的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成风险，而生物医学声明验证因复杂术语、领域专业知识和科学证据基础需求而具有独特挑战性。

Method: CER框架整合科学证据检索、通过大语言模型进行推理，以及监督真实性预测，将大语言模型的文本生成能力与高质量生物医学科学证据的先进检索技术相结合。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示达到了最先进的性能，并展现出有前景的跨数据集泛化能力。

Conclusion: CER框架通过将生成输出基于可验证的证据来源，有效减轻了幻觉风险，代码和数据已开源以确保透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [23] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER框架结合科学证据检索、大语言模型推理和监督真实性预测，在生物医学事实核查中实现最先进性能，有效减少幻觉风险。


<details>
  <summary>Details</summary>
Motivation: 医疗领域错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成威胁。生物医学声明验证具有术语复杂、需要领域专业知识、必须基于科学证据等独特挑战。

Method: 提出CER框架，整合科学证据检索、大语言模型推理和监督真实性预测。通过结合大语言模型的文本生成能力和高质量生物医学科学证据的检索技术，确保输出基于可验证的证据来源。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示达到最先进性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架为生物医学事实核查提供了有效解决方案，通过证据检索和语言模型推理的结合，显著提升了自动化事实核查的准确性和可靠性，代码和数据已开源以确保透明度和可重现性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [24] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 该论文评估了大语言模型在词义消歧任务中的表现，发现GPT-4o和DeepSeek-V3等领先模型与专门WSD系统性能相当，且在生成任务中能达到98%的准确率。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量评估工作，但大语言模型是否真正理解词义仍未被充分探索，需要系统评估其在词义消歧和词义理解生成任务中的能力。

Method: 评估指令调优LLMs的词义消歧能力，并与专门WSD系统比较；评估两个顶级开源和闭源LLMs在三种生成任务中的表现：定义生成、自由形式解释和示例生成。

Result: 在WSD任务中，GPT-4o和DeepSeek-V3与专门WSD系统性能相当，且在不同领域和难度级别上表现更稳健；在生成任务中，LLMs能以前后文准确解释词义，最高准确率达98%，自由形式解释任务表现最佳。

Conclusion: 大语言模型在词义理解和消歧方面表现出色，能够达到与专门系统相当的性能，并且在生成解释方面展现出强大的能力，特别是在自由形式的解释任务中。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [25] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 研究发现多语言RAG系统中存在英语偏好偏见，模型会优先引用英语文档而非最相关的文档，特别是在低资源语言和上下文中间位置时更明显


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成系统中不同语言文档混合是否会对生成和引用行为产生意外影响，特别是语言偏好是否会影响引用选择

Method: 使用模型内部机制的控制方法，在保持文档相关性等其他因素不变的情况下测量语言偏好，涵盖8种语言和6个开源模型

Result: 模型在英语查询时优先引用英语来源，这种偏见在低资源语言和位于上下文中间的文档中更加明显；模型有时会牺牲文档相关性来满足语言偏好

Conclusion: 引用选择并非总是由信息量驱动，语言偏好显著影响多语言上下文中的引用行为，这对多语言RAG系统的设计和评估具有重要意义

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [26] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 基于COMET框架构建的翻译质量评估系统，通过长上下文数据增强训练，预测错误跨度标注分数，在WMT25评测中表现优于短片段模型


<details>
  <summary>Details</summary>
Motivation: 现有的翻译质量评估系统主要基于短片段训练，缺乏对长上下文信息的利用，而长上下文信息可能有助于提高评估准确性

Method: 1) 使用领域内人工标注句子构建长上下文训练数据，计算加权平均分数；2) 整合多种人工标注数据集(MQM、SQM、DA)，通过尺度归一化处理；3) 训练多语言回归模型，基于源文本、假设翻译和参考翻译预测质量分数

Result: 实验结果表明，引入长上下文信息的模型相比仅使用短片段训练的模型，与人工评估的相关性更高

Conclusion: 长上下文信息对翻译质量评估具有重要价值，基于COMET框架的长上下文训练方法能有效提升评估性能

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [27] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: Slim-SC是一种新的测试时缩放技术，通过逐步剪枝策略减少Self-Consistency中的冗余推理链，在保持或提高准确性的同时显著降低计算开销


<details>
  <summary>Details</summary>
Motivation: Self-Consistency虽然有效但计算开销巨大，现有加速方法主要依赖模型置信度分数或缺乏实证支持的启发式方法，需要更高效的解决方案

Method: 提出Slim-SC方法，在思维层面使用链间相似性识别和移除冗余推理链，采用逐步剪枝策略

Result: 在三个STEM推理数据集和两种LLM架构上，Slim-SC将推理延迟降低45%，KVC使用降低26%，同时保持或提高准确性

Conclusion: Slim-SC为Self-Consistency提供了一个简单而高效的替代方案，在显著减少计算资源消耗的同时维持了推理性能

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [28] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 该研究提出了一种基于证据检索的不确定性感知决策机制，通过查找近似示例并融合其预测分布来实现供供透明可审计的适应性决策阅刻。


<details>
  <summary>Details</summary>
Motivation: 替代单一全局阅刻标准，提供一种基于证据的适应性决策机制，以实现更可靠和可解释的不确定性感知决策。

Method: 为每个测试实例在嵌入空间中查找近似示例，通过Dempster-Shafer理论融合其预测分布，形成融合信念作为每个实例的阅刻机制。

Result: 在CIFAR-10/100上使用BiT和ViT背榜进行实验，显示了更高或相似的不确定性感知性能，同时减少了自信错误的结果，并保持可持续的审查负荷。仅需少量证据即可实现这些收益。

Conclusion: 证据条件化标记提供了比固定预测熵阅刻更可靠和可解释的替代方案，适用于操作性不确定性感知决策。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [29] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确率、训练效率和参数可扩展性方面优于纯经典模型，特别是在复杂视觉任务中表现突出


<details>
  <summary>Details</summary>
Motivation: 系统比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性方面的差异，评估量子计算在深度学习中的实际价值

Method: 在MNIST、CIFAR100和STL10三个基准数据集上，将参数化量子电路与经典深度学习架构结合的混合模型与传统的卷积神经网络进行对比实验，训练50个epoch，评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性

Result: 混合模型在所有数据集上准确率均优于经典模型（MNIST: 99.38% vs 98.21%；CIFAR100: 41.69% vs 32.25%；STL10: 74.05% vs 63.76%），训练速度快5-12倍，参数减少6-32%，内存使用更低（4-5GB vs 5-6GB），CPU利用率更低（9.5% vs 23.2%），在简单数据集上对抗鲁棒性显著更好

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有显著优势，特别适用于复杂视觉任务，为量子计算在深度学习中的应用提供了有力证据

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [30] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 通过优化YOLOv11-DIoU和DeepSort算法提高遮挡情况下的车辆检测准确性，并使用GRU-Attention模型进行拒塞预警，在高速公路拒塞管理中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有"检测-预测"系统在遮挡条件下车辆感知准确性低和拒塞预测中长序列依赖失失的关键缺陷。

Method: 1）优化YOLOv11为YOLOv11-DIoU（替换GIoU Loss为DIoU Loss）和DeepSort（融合马洋海斯距离和余弦距离）提高车辆检测性能
2）使用Greenberg模型分析高密度场景下速度与密度关系
3）构建GRU-Attention模型进行拒塞预警，训练300连续时间步长

Result: 1）YOLOv11-DIoU达到95.7% mAP（比基线提高6.5%），906e挡漏检率仅5.3%
2）DeepSort达到93.8% MOTA（比SORT提高11.3%），仅4次ID切换
3）速度与密度呈强负相关（r=-0.97）
4）GRU-Attention模型测试准确率达99.7%（比传统GRU提高7-9%），10分钟预譢错差≤1分钟
5）独立视频验证95%预警准确率，>90%拒塞点空间重叠率

Conclusion: 该集成框架为高速公路拒塞控制提供了量化支撑，在智能交通预警预测方面具有应用潜力。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [31] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 通过深度学习和卷积神经网络自动化地面真实测试过程，将人力芯耗减少99.58%，提升了基于群晶数据的实时路边停车服务质量


<details>
  <summary>Details</summary>
Motivation: 优化现有的路边停车服务质量，通过自动化地面真实测试过程来替代人工工作，提高效率和减少人力芯耗

Method: 采用机器学习和图像模式识别技术，特别是卷积神经网络(CNN)，来完善数据库并自动化分析过程

Result: 实现了高度自动化水平，人力资源时间消耗减少99.58%，显著提升了分析效率

Conclusion: 研究成功开发了一个高度自动化的分析工具，为未来的服务优化和更广泛的应用提供了基础，显示了深度学习在实际应用中的巨大潜力

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [32] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了视觉语言模型(VLMs)在零样本分布外检测中的机制、优势和敏感性，揭示了其利用语义新颖性的优势，但对提示词措辞高度敏感的关键脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型(如CLIP)在零样本分布外检测方面表现出色，但研究界对其工作机制、相对于单模态方法的优势以及行为鲁棒性缺乏全面理解。

Method: 通过系统性的实证分析，使用分布内和分布外提示词，从三个维度研究VLM-based OOD检测：机制特性形式化、优势量化比较、敏感性分析。

Result: 发现VLM能够利用丰富的语义新颖性，在OOD检测上优于单模态方法；同时揭示了不对称的鲁棒性特征：对图像噪声具有韧性，但对提示词措辞高度敏感。

Conclusion: 研究提供了对VLM-based OOD检测优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [33] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 提出基于截面曲率概念的离散度量空间几何分析方法，构建曲率剖面来评估数据表示效果和估计数据集本征维度


<details>
  <summary>Details</summary>
Motivation: 利用新发展的截面曲率抽象概念来分析离散度量空间的几何特性，为评估降维技术效果和探索经验网络的大规模几何结构提供定量工具

Method: 基于捕获点三元组与其他点之间度量关系的曲率概念，构建曲率剖面来分析数据表示

Result: 实验证明该方法可用于估计数据集的本征维度，探索经验网络的大规模几何结构，并评估降维技术的有效性

Conclusion: 曲率分析方法为离散度量空间的几何分析提供了有效工具，特别在评估数据表示质量和维度估计方面具有实用价值

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [34] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 使用机器学习和遥感技术分析斜蒂治纳迪市2013-2024年土地利用变化，为城市化监测提供技术支持


<details>
  <summary>Details</summary>
Motivation: 斜蒂纳迪作为发展中国家正经历快速城市化，需要监测土地利用变化以支持城市规划和发展项目

Method: 使用Landsat-8卫星图像，通过Google Earth Engine和k-means聚类进行无监督分类，使用卷积神经网络进行有监督分类，生成土地覆盖图

Result: 建立了土地利用变化监测可视化系统，显示了城市区域随时间的变化趋势

Conclusion: 研究为斜蒂纳迪的土地覆盖模型和变化监测提供了有效的技术支持方法，有助于城市发展规划和环境管理

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [35] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 基于YOLOv7分割和ConvNeXt特征提取的三阶段框架，实现了对电力传输系统中异物入侵的实时检测与跟踪，支持边缘设备部署和增量更新。


<details>
  <summary>Details</summary>
Motivation: 解决电力传输系统中异物入侵检测的实时性、准确性和遥锐性问题，适应复杂场景下的遮捏和运动情况。

Method: 1）YOLOv7分割模型进行快速物体定位 2）ConvNeXt基于三元组损失训练的特征提取器 3）特征辅助IoU跟踪器处理遮捏和多物体跟踪

Result: 在真实监控和无人机视频数据集上高准确性和遥锐性，NVIDIA Jetson边缘设备上验证了实际可行性。

Conclusion: 该框架为电力传输安全提供了高效、可扩展的实时监控解决方案，具有重大应用价值。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [36] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: EdiVal-Agent是一个自动化的多轮指令图像编辑评估框架，通过对象中心视角和专家工具套件提供细粒度评估，解决了当前评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑评估存在两个主要问题：(i)依赖配对参考图像导致覆盖范围有限且继承生成模型偏见，(ii)仅依赖零样本视觉语言模型的评估往往不精确。需要更可靠和可解释的评估方法。

Method: EdiVal-Agent首先将图像分解为语义对象，然后合成多样化的上下文感知编辑指令。评估时结合VLM与开放词汇对象检测器评估指令遵循，使用语义级特征提取器评估内容一致性，并利用人类偏好模型判断视觉质量。

Result: 研究表明，将VLM与对象检测器结合使用在指令遵循评估中比单独使用VLM和基于CLIP的指标更能与人类判断达成一致。模块化设计允许未来工具无缝集成。

Conclusion: EdiVal-Agent框架能够识别现有编辑模型的失败模式，为下一代编辑模型的开发提供信息，并建立了EdiVal-Bench基准测试，覆盖9种指令类型和11种最先进的编辑模型。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [37] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的基于Transformer的前馈模型，能够处理单张或多张图像以及可选几何输入，直接回归度量3D场景几何和相机参数，在多种3D视觉任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D视觉任务中需要专门模型的问题，开发一个统一的模型来处理多种3D重建任务，提高效率和泛化能力。

Method: 使用基于Transformer的前馈架构，输入图像和可选几何信息，采用分解的多视角场景几何表示（深度图、局部射线图、相机位姿和度量尺度因子），通过标准化监督和灵活输入增强进行训练。

Result: 在多个3D视觉任务中优于或匹配专门的前馈模型，提供更高效的联合训练性能，包括未标定SfM、标定多视角立体、单目深度估计、相机定位等任务。

Conclusion: MapAnything为通用3D重建主干网络铺平了道路，展示了统一模型在多样化3D视觉任务中的强大潜力。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [38] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，通过融合RGB图像的语义信息来提升在LiDAR地图中的跨模态定位性能，解决现有方法在复杂场景、细粒度匹配和视角变化下的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-based视觉地点识别方法对光照、天气和季节变化敏感，而现有跨模态定位方法在复杂场景、细粒度匹配和视角变化下表现不佳，需要更鲁棒的定位解决方案。

Method: 使用VMamba骨干网络提取RGB图像特征；提出语义感知特征融合模块(SAFF)结合地点描述符和分割掩码；设计包含语义和几何信息的LiDAR描述符；在NetVLAD中引入跨模态语义注意力机制；在对比学习框架中设计多视角语义-几何匹配和语义一致性损失。

Result: 在KITTI和KITTI-360数据集上的实验表明，SCM-PR相比其他跨模态地点识别方法达到了最先进的性能。

Conclusion: 通过融合高级语义信息，SCM-PR框架显著提升了跨模态地点识别的鲁棒性和准确性，特别是在复杂场景和视角变化条件下。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [39] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 提出场景自适应格点向量量化(SALVQ)方法替代均匀标量量化，提升3D高斯泼溅压缩性能，支持多码率目标且无需重新训练


<details>
  <summary>Details</summary>
Motivation: 3DGS生成大量数据需要压缩，现有基于锚点的神经压缩方法都使用简单的均匀标量量化，需要探索更先进的量化器来提升压缩性能

Method: 使用格点向量量化(LVQ)替代均匀标量量化，并为每个场景优化格点基向量，实现场景自适应LVQ(SALVQ)，通过缩放格点基向量动态调整格点密度

Result: SALVQ在保持低复杂度的同时提升了率失真效率，可无缝集成到现有3DGS压缩架构中，显著减少训练时间和内存消耗

Conclusion: SALVQ方法有效平衡了向量量化的率失真效率和均匀标量量化的低复杂度，为3DGS压缩提供了灵活高效的解决方案

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [40] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 提出了MINGLE方法，通过三阶段管道检测图像中的社交群体区域，包括人体检测、VLM社交关系分类和空间聚合算法，并发布了包含10万张街景图像的新数据集


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，需要超越传统物体检测来解读复杂的社会信号

Method: 三阶段模块化管道：1)现成的人体检测和深度估计 2)VLM基础的成对社交关系分类 3)轻量级空间聚合算法定位社交连接群体

Result: 构建了包含10万张城市街景图像的新数据集，标注了个人和社交群体的边界框和标签，结合人工标注和MINGLE输出

Conclusion: 提出了社交群体区域检测新任务和MINGLE方法，为未来研究提供了数据集和方法基础

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [41] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏见，通过交叉注意力归因图揭示人口统计特征与语义概念的结构性纠缠，并提出基于能量引导扩散采样的偏见缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注输出层面的人口统计分布，无法保证偏见缓解后概念表征的解耦。需要更深入地揭示图像生成过程中的表征偏见。

Method: 利用交叉注意力归因图量化人口统计-语义概念的空间纠缠（通过IoU指标），并采用能量引导扩散采样在去噪过程中直接修改潜在噪声空间以最小化SoftIoU期望值。

Result: 研究发现现有公平性干预可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap的缓解方法能够在图像生成中减轻概念纠缠，同时补充分布偏见缓解。

Conclusion: BiasMap提供了一个发现和缓解潜在概念级表征偏见的新框架，能够揭示现有公平性发现方法中隐藏的偏见，并通过直接操作潜在空间实现更有效的偏见解耦。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [42] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePixel是一个基于Python的实时图像标注工具，可直接连接成像设备进行实时标注，支持贝塞尔曲线和二进制掩码等专业标注功能


<details>
  <summary>Details</summary>
Motivation: 现有图像标注工具需要先上传预收集数据集，无法支持实时数据采集和按需标注，这在实验室实时仪器数据采集场景中尤为不便

Method: 开发Python图形用户界面，集成OpenCV和Numpy等高性能库，支持多种视频设备连接，提供类似商业图形软件的标注工具和非破坏性图层编辑

Result: 实现了实时图像标注功能，支持贝塞尔曲线、二进制掩码等专业标注工具，与显微镜、网络摄像头等成像设备无缝集成

Conclusion: LivePixel解决了科学领域AI模型部署中的标注工具限制问题，通过实时标注加速实验工作流中的AI模型开发

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [43] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 提出DEFT-VTON方法，通过Doob's h-transform高效微调预训练扩散模型，仅训练1.42%参数实现虚拟试穿，结合自适应一致性损失将推理步骤减少至15步，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法需要大量端到端训练，但实际应用需要有限的训练和推理资源预算。需要开发参数高效且推理快速的解决方案。

Method: 使用DEFT冻结预训练模型参数，训练小型h-transform网络学习条件变换；提出自适应一致性损失，结合一致性损失和去噪分数匹配损失进行低成本微调。

Result: DEFT-VTON在虚拟试穿任务上达到最先进性能，仅需15个去噪步骤，参数量仅为传统PEFT方法的1.42%（对比5.52%）。

Conclusion: 该方法成功解决了虚拟试穿应用中的计算资源限制问题，实现了高效参数微调和快速推理，为实际部署提供了可行方案。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [44] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 使用数据增强和对抗学习生成合成交通场景，提高行人识别性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要合成数据覆盖特定交通场景，但合成数据与真实数据存在领域差距，需要提高行人识别的准确性

Method: 开发数据增强管道，在Cityscapes数据集中添加虚拟行人；提出新颖的生成对抗网络架构，学习数据集光照条件以提高增强真实性

Result: 在语义分割和实例分割任务上评估了该方法

Conclusion: 通过数据增强和对抗学习技术，能够生成更真实的合成交通场景，有效改善行人识别性能

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [45] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了FunKAN网络，一种专门为图像处理设计的可解释神经网络框架，在医学图像增强和分割任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法架构复杂且可解释性有限，而Kolmogorov-Arnold网络虽然可解释但会破坏图像的空间结构特征

Method: 基于函数空间推广Kolmogorov-Arnold表示定理，使用Hermite函数的傅里叶分解学习内部函数，提出了FunKAN和U-FunKAN模型

Result: 在多个医学数据集上验证，包括IXI（MRI去伪影）、BUSI（乳腺癌检测）、GlaS（腺体分割）、CVC-ClinicDB（息肉检测），在PSNR、TV、IoU、F1等指标上优于其他KAN方法

Conclusion: 该工作填补了理论函数逼近与医学图像分析之间的空白，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [46] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种多模态双流图神经网络模型，通过构建实例图和补充权重图来精确检测偷恶视频，在公开数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检测方法忽视了轻微的偷恶内容也能定义视频类别，且无法系统地抓取视频中的结构化信息，限制了多模态融合的效果。

Method: 提出多模态双流图神经网络模型，通过将视频分割为多个实例来构建实例图提取实例级特征，然后使用补充权重图为这些特征赋予重要性权重，强调偷恶实例，最后结合权重和特征生成视频标签。

Result: 在公开数据集上的实验表明，该模型在偷恶视频分类任务上达到了最先进的性能，并具有强的可解释性。

Conclusion: 该研究提出的图基框架模型能够有效地检测偷恶视频，通过强调偷恶内容和系统地模式化多模态关系，为在线安全领域提供了有效的解决方案。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [47] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的深度估计方法，能够从单目结肠镜视频生成时间一致性的深度图，在C3VD数据集上实现了零样本最先进性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜三维场景理解面临重大挑战，现有深度估计模型在视频序列中缺乏时间一致性，限制了其在3D重建中的应用。

Method: 使用基于扩散的深度估计模型，从合成结肠镜序列学习几何先验来生成时间一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域。

Result: 在C3VD数据集上实现了零样本最先进的性能，优于通用和结肠镜专用方法，展示了3D点云生成和表面覆盖评估等临床应用。

Conclusion: 虽然完整轨迹的3D重建仍然具有挑战性，但ColonCrafter在临床相关应用中表现出色，为结肠镜深度估计提供了有效的解决方案。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [48] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 通过基于几何相似性的汇编算法和表面样本采集方法，在不影响渲染性能的前提下，降低了3D高斯分散GPU内存占用并提升了渲染质量


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式平台（如微型飞行器）在3D高斯分散技术中遇到的计算资源和内存限制问题，在保持系统性能的同时提升重建质量

Method: 1）在汇编空间中基于几何相似性合并冗余的3D高斯原语；2）通过表面样本采集方法初始化3D高斯原语，以更准确地建模整个场景

Result: 在公开数据集上进行的定量和定性评估显示，该方法能够有效降低GPU内存占用并提升渲染质量

Conclusion: 该研究为嵌入式平台提供了一种高效的3D高斯分散方案，在不缩减运行性能的前提下实现了内存优化和质量提升

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [49] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种用于自动驾驶车辆轨迹预测的自适应OOD检测框架，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署中面临训练数据与现实条件之间的分布偏移问题，现有OOD检测研究主要集中在计算机视觉任务，轨迹级别的OOD检测研究相对不足。

Method: 基于快速变化检测(QCD)任务，引入自适应机制，显式建模预测误差的模式依赖性分布及其随时间演化的特性。

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面取得显著改进，在准确性和计算效率上均优于现有的UQ和基于视觉的OOD方法。

Conclusion: 该框架为可靠、驾驶感知的自主性提供了一条实用路径，能够有效处理复杂驾驶环境中的分布偏移问题。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [50] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的亚马逊雨林砍伐检测方法，通过卫星图像对比和视觉语义模型自动标注变化区域


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林砍伐对全球碳排放和生物多样性有重大影响，需要有效的监测工具来研究和应对这一环境问题

Method: 利用地球观测卫星图像对，采用深度学习技术比较不同时间点的同一区域图像，识别森林覆盖变化，并结合科学文献提取关键词构建视觉语义模型进行自动标注

Result: 在亚马逊图像对数据集上验证了方法的有效性，能够准确检测砍伐并生成相关标注

Conclusion: 该方法为监测和研究亚马逊砍伐影响提供了有用工具，虽然以环境应用为重点展示，但具有通用性可应用于其他领域

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>
